{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/geeky-programer/LLM/blob/main/Intro_langchain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rIoWHuU-gAdG"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vSH9UJHehAwc",
        "outputId": "0fba5555-f989-4f3d-dfa1-ac252545bad0"
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGH9FOB-hs_y",
        "outputId": "b5072565-3cc8-4acf-a459-6879ae37884b"
      },
      "outputs": [],
      "source": [
        "llm=OpenAI(temperature=0.6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bs32aFP_iF0Q",
        "outputId": "61bdd2e9-ef60-4005-c75c-24b5c76d8b91"
      },
      "outputs": [],
      "source": [
        "text = \"what is the capital of India\"\n",
        "\n",
        "print(llm.predict(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-boGabxjXm_"
      },
      "outputs": [],
      "source": [
        "from langchain import HuggingFaceHub\n",
        "llm_hug = HuggingFaceHub(repo_id=\"google/flan-t5-large\",model_kwargs={\"temperature\":0,\"max_length\":64})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2DF506fJkGCm",
        "outputId": "e5eeb224-94a1-4549-9187-b786a8d58e24"
      },
      "outputs": [],
      "source": [
        "llm_hug.predict(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "cvYs2h-clg58",
        "outputId": "66d66c13-8ba2-485f-f232-eb9dd5a9ddf1"
      },
      "outputs": [],
      "source": [
        "## prompt templates\n",
        "\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "prompt_template = PromptTemplate(input_variables=['country'], template=\"Tell me the capital of this {country}\")\n",
        "\n",
        "prompt_template.format(country='India')\n",
        "\n",
        "from langchain.chains import LLMChain\n",
        "chain = LLMChain(llm=llm, prompt = prompt_template)\n",
        "chain.run(\"India\")\n",
        "\n",
        "## chain --> LLM model + prompt template\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZsJmWlpmn3z"
      },
      "outputs": [],
      "source": [
        "### multiple chains & simple sequential chains\n",
        "\n",
        "\n",
        "capital_template = PromptTemplate(input_variables=[\"country\"], template = \"Please tell me the capital of {country}\")\n",
        "\n",
        "capital_chain = LLMChain(llm=llm, prompt=capital_template)\n",
        "\n",
        "\n",
        "famous_template = PromptTemplate(input_variables=[\"capital\"], template = \"suggest me places to visit {capital}\")\n",
        "\n",
        "famous_chain = LLMChain(llm=llm,prompt=famous_template)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "5gIJqFqWonKL",
        "outputId": "fb974773-9c1c-4fee-9f71-a880d918bcae"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import SimpleSequentialChain\n",
        "chain = SimpleSequentialChain(chains =[capital_chain, famous_chain])\n",
        "chain.run(\"India\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FamaUA_GpAa6"
      },
      "outputs": [],
      "source": [
        "capital_template = PromptTemplate(input_variables=[\"country\"], template = \"Please tell me the capital of {country}\")\n",
        "\n",
        "capital_chain = LLMChain(llm=llm, prompt=capital_template, output_key=\"capital\")\n",
        "\n",
        "famous_template = PromptTemplate(input_variables=[\"capital\"], template = \"suggest me places to visit {capital}\")\n",
        "\n",
        "famous_chain = LLMChain(llm=llm,prompt=famous_template,output_key=\"places\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bs1UgJs0rlns"
      },
      "outputs": [],
      "source": [
        "from langchain.chains.sequential import SequentialChain\n",
        "chain = SequentialChain(chains = [capital_chain, famous_chain], input_variables=['country'], output_variables = ['capital', 'places'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vy1XXD-4sDX0",
        "outputId": "fd0fb1c5-68f5-4f8b-fd3e-9f67506ac7f7"
      },
      "outputs": [],
      "source": [
        "chain({'country':'India'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQ6r6QHSC0vh"
      },
      "outputs": [],
      "source": [
        "###chat bots with Openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uxy3xuoiC0Zy"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YaU5PhYcEspG"
      },
      "outputs": [],
      "source": [
        "from langchain.schema import HumanMessage,SystemMessage,AIMessage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luewGTomEucX",
        "outputId": "bdcb6d07-a2ae-4a59-dd99-fbd6e1aeac87"
      },
      "outputs": [],
      "source": [
        "chatllm=ChatOpenAI(temperature=0.6,model='gpt-3.5-turbo')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fydxKUPSFG8h",
        "outputId": "8903843e-0fdc-4980-86c8-8d6aaa2cf94d"
      },
      "outputs": [],
      "source": [
        "chatllm([\n",
        "SystemMessage(content=\"Yor are a professor AI learning\"),\n",
        "HumanMessage(content=\"Please provide insights on deep learning and a guide to learn it\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UhXYiLpDFZbR"
      },
      "outputs": [],
      "source": [
        "## prompt template ++ LLM ++ Output parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tK1Wxp7F43o"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts.chat import ChatPromptTemplate\n",
        "from langchain.schema import BaseOutputParser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kai43j9xGe6F"
      },
      "outputs": [],
      "source": [
        "class Commaseparatedoutput(BaseOutputParser):\n",
        "    def parse(self, text:str):\n",
        "      return text.strip().split(',')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LPsh2r-G0Ib"
      },
      "outputs": [],
      "source": [
        "template = \"you are a helpful assistant. When the user gives any input you should generated 5 words synonyms which are comma separated\"\n",
        "human_template = \"{text}\"\n",
        "chatprompt = ChatPromptTemplate.from_messages([('system',template),('human',human_template)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Phq25mXuHgJa"
      },
      "outputs": [],
      "source": [
        "chain = chatprompt|chatllm|Commaseparatedoutput()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uf0M4SkH-Jh",
        "outputId": "f8d35487-a02f-4b20-d335-588e5eaf2e23"
      },
      "outputs": [],
      "source": [
        "chain.invoke({'text':'intelligent'})"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPAczHofK6X6qkGfCiQ4L6/",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
